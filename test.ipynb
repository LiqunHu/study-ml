{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1849cfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import timeit\n",
    "from jaxtyping import Float\n",
    "from einops import rearrange, einsum, reduce\n",
    "from typing import Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c49540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.Size([4, 8])\n",
      "32\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(4,8)\n",
    "print(x.dtype)\n",
    "print(x.size())\n",
    "print(x.numel())\n",
    "print(x.element_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b60ce266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "tensor([0.], dtype=torch.float16)\n",
      "tensor([1.0012e-08], dtype=torch.bfloat16)\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "x=torch.zeros(4,8,dtype=torch.float16)\n",
    "print(x.element_size())\n",
    "x=torch.tensor([1e-8], dtype=torch.float16)\n",
    "print(x)\n",
    "x=torch.tensor([1e-8], dtype=torch.bfloat16)\n",
    "print(x)\n",
    "print(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38fede3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "1\n",
      "512\n",
      "mps:0\n",
      "4096\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.mps.is_available())\n",
    "num_gpus = torch.mps.device_count()\n",
    "print(num_gpus)\n",
    "memory_allocated = torch.mps.current_allocated_memory()\n",
    "print(memory_allocated)\n",
    "x=torch.zeros(4,8,dtype=torch.float16)\n",
    "y = x.to('mps')\n",
    "print(y.device)\n",
    "z = torch.zeros(32,32, device=\"mps\")\n",
    "new_memory_allocated = torch.mps.current_allocated_memory()\n",
    "memory_used = new_memory_allocated - memory_allocated\n",
    "print(memory_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "560327f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[0.,1,2,3],[4,5,6,7],[8,9,10,11],[12,13,14,15]])\n",
    "print(x.stride(0))\n",
    "print(x.stride(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f681976f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "True\n",
      "tensor([2., 5.])\n",
      "True\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "True\n",
      "tensor([[1., 4.],\n",
      "        [2., 5.],\n",
      "        [3., 6.]])\n",
      "True\n",
      "tensor(100.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1.,2,3],[4,5,6]])\n",
    "y= x[0]\n",
    "print(y)\n",
    "print(x.untyped_storage().data_ptr() == y.untyped_storage().data_ptr())\n",
    "\n",
    "y = x[:, 1]\n",
    "print(y)\n",
    "print(x.untyped_storage().data_ptr() == y.untyped_storage().data_ptr())\n",
    "\n",
    "y = x.view(3,2)\n",
    "print(y)\n",
    "print(x.untyped_storage().data_ptr() == y.untyped_storage().data_ptr())\n",
    "\n",
    "y= x.transpose(1,0)\n",
    "print(y)\n",
    "print(x.untyped_storage().data_ptr() == y.untyped_storage().data_ptr())\n",
    "\n",
    "x[0][0] = 100\n",
    "print(y[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c10702a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 4.],\n",
      "        [2., 5.],\n",
      "        [3., 6.]])\n",
      "False\n",
      "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.\n",
      "tensor([[1., 4., 2.],\n",
      "        [5., 3., 6.]])\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1.,2,3],[4,5,6]])\n",
    "y = x.transpose(1,0)\n",
    "print(y)\n",
    "print(y.is_contiguous())\n",
    "try:\n",
    "    y.view(2,3)\n",
    "except RuntimeError as e:\n",
    "    print(str(e))\n",
    "\n",
    "y=x.transpose(1,0).contiguous().view(2,3)\n",
    "print(y)\n",
    "print(x.untyped_storage().data_ptr() == y.untyped_storage().data_ptr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575764db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1, 16, 81])\n",
      "tensor([1., 2., 3.])\n",
      "tensor([1.0000, 0.5000, 0.3333])\n",
      "tensor([ 2,  8, 18])\n",
      "tensor([ 2,  8, 18])\n",
      "tensor([ 2.,  8., 18.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,4,9])\n",
    "print(x.pow(2))\n",
    "print(x.sqrt())\n",
    "print(x.rsqrt())\n",
    "print(x+x)\n",
    "print(x*2)\n",
    "print(x/0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3f0892a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [0., 1., 1.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(3,3).triu()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b00b405d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 1)\n",
      "(2, 1)\n",
      "(2, 1)\n",
      "torch.Size([16, 2])\n",
      "torch.Size([4, 8, 16, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(16,32)\n",
    "print(x.stride())\n",
    "y = torch.ones(32,2)\n",
    "print(y.stride())\n",
    "z = x @ y\n",
    "print(z.stride())\n",
    "print(z.size())\n",
    "x = torch.ones(4,8,16,32)\n",
    "y = torch.ones(32,2)\n",
    "z = x @ y\n",
    "print(z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70968cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 2, 2])\n",
      "(8, 4, 2, 1)\n",
      "torch.Size([2, 2, 2, 2])\n",
      "(8, 1, 2, 4)\n"
     ]
    }
   ],
   "source": [
    "# test transpose\n",
    "x = torch.tensor(\n",
    "    [[[[1, 2], [3, 4]], [[5, 6], [7, 8]]], [[[9, 10], [11, 12]], [[13, 14], [15, 16]]]]\n",
    ")\n",
    "print(x.size())\n",
    "print(x.stride())\n",
    "y = x.transpose(1, -1)\n",
    "print(y.size())\n",
    "print(y.stride())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adddee31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 3, 1)\n",
      "(6, 3, 1)\n",
      "(6, 1, 3)\n",
      "torch.Size([2, 3, 3])\n",
      "(3, 1)\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "(3, 1)\n",
      "tensor([[4., 4., 4.],\n",
      "        [4., 4., 4.]])\n",
      "(24, 8, 4, 1)\n",
      "tensor([[[[1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.]]]])\n",
      "(24, 8, 4, 1)\n",
      "tensor([[[[4., 4., 4., 4.],\n",
      "          [4., 4., 4., 4.]],\n",
      "\n",
      "         [[4., 4., 4., 4.],\n",
      "          [4., 4., 4., 4.]],\n",
      "\n",
      "         [[4., 4., 4., 4.],\n",
      "          [4., 4., 4., 4.]]],\n",
      "\n",
      "\n",
      "        [[[4., 4., 4., 4.],\n",
      "          [4., 4., 4., 4.]],\n",
      "\n",
      "         [[4., 4., 4., 4.],\n",
      "          [4., 4., 4., 4.]],\n",
      "\n",
      "         [[4., 4., 4., 4.],\n",
      "          [4., 4., 4., 4.]]]])\n",
      "(24, 8, 1)\n",
      "tensor([[[4., 4., 4., 4., 4., 4., 4., 4.],\n",
      "         [4., 4., 4., 4., 4., 4., 4., 4.],\n",
      "         [4., 4., 4., 4., 4., 4., 4., 4.]],\n",
      "\n",
      "        [[4., 4., 4., 4., 4., 4., 4., 4.],\n",
      "         [4., 4., 4., 4., 4., 4., 4., 4.],\n",
      "         [4., 4., 4., 4., 4., 4., 4., 4.]]])\n"
     ]
    }
   ],
   "source": [
    "# einops\n",
    "x = torch.ones(2, 2, 3)\n",
    "print(x.stride())\n",
    "y = torch.ones(2, 2, 3)\n",
    "print(y.stride())\n",
    "z = y.transpose(-2, -1)   \n",
    "print(z.stride())\n",
    "z = x @ y.transpose(-2, -1)\n",
    "\n",
    "# einsum\n",
    "x: Float[torch.Tensor, \"batch seq1 hidden\"] = torch.ones(2, 3, 4)\n",
    "y: Float[torch.Tensor, \"batch seq2 hidden\"] = torch.ones(2, 3, 4)\n",
    "\n",
    "#z = x @ y.transpose(-2,-1)\n",
    "\n",
    "z = einsum(x, y, \"batch seq1 hidden, batch seq2 hidden -> batch seq1 seq2\")\n",
    "print(z.size())\n",
    "\n",
    "# reduce\n",
    "y = x.mean(-1)\n",
    "print(y.stride())\n",
    "print(y)\n",
    "\n",
    "y = reduce(x, \"... hidden -> ...\", \"sum\")\n",
    "print(y.stride())\n",
    "print(y)\n",
    "\n",
    "# rearrange\n",
    "x: Float[torch.Tensor, \"batch seq total_hidden\"] = torch.ones(2, 3, 8)\n",
    "w: Float[torch.Tensor, \"hidden1 hidden2\"] = torch.ones(4, 4)\n",
    "\n",
    "x = rearrange(x, \"... (heads hidden1) -> ... heads hidden1\", heads = 2)\n",
    "print(x.stride())\n",
    "print(x)\n",
    "\n",
    "x = einsum(x, w, \"... hidden1, hidden1 hidden2 -> ... hidden2\")\n",
    "print(x.stride())\n",
    "print(x)\n",
    "\n",
    "x = rearrange(x, \"... heads hidden2 -> ... (heads hidden2)\")\n",
    "print(x.stride())\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97b7a520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_matmul(a: torch.Tensor, b: torch.Tensor) -> float:\n",
    "    \"\"\"Return the number of seconds required to perform `a @ b`.\"\"\"\n",
    "    # Wait until previous CUDA threads are done\n",
    "    if torch.mps.is_available():\n",
    "        torch.mps.synchronize()\n",
    "    def run():\n",
    "        # Perform the operation\n",
    "        a @ b\n",
    "        # Wait until CUDA threads are done\n",
    "        if torch.mps.is_available():\n",
    "            torch.mps.synchronize()\n",
    "    # Time the operation `num_trials` times\n",
    "    num_trials = 5\n",
    "    total_time = timeit.timeit(run, number=num_trials)\n",
    "    return total_time / num_trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ce5467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4450460492667.393\n",
      "4537461470868.2295\n"
     ]
    }
   ],
   "source": [
    "B = 16384  # Number of points\n",
    "D = 32768  # Dimension\n",
    "K = 8192   # Number of outputs\n",
    "device = torch.device(\"mps\")\n",
    "x = torch.ones(B, D, device=device)\n",
    "w = torch.randn(D, K, device=device)\n",
    "\n",
    "actual_num_flops = 2 * B * D * K\n",
    "\n",
    "# actual_time = time_matmul(x, w)\n",
    "# actual_flop_per_sec = actual_num_flops / actual_time \n",
    "# print(actual_flop_per_sec)\n",
    "\n",
    "x.to(torch.bfloat16)\n",
    "w.to(torch.bfloat16)\n",
    "actual_time = time_matmul(x, w)\n",
    "actual_flop_per_sec = actual_num_flops / actual_time \n",
    "print(actual_flop_per_sec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e87ea83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.,2,3])\n",
    "w = torch.tensor([1.,1,1], requires_grad=True)\n",
    "pred_y = x @ w\n",
    "loss = 0.5 * (pred_y -5).pow(2)\n",
    "loss.backward()\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ea92c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "<class 'torch.Tensor'>\n",
      "tensor([ -73.4144, -200.6748,  134.5749,  -77.8689,  148.2784,   45.0297,\n",
      "         168.0362,  -79.4507,   59.3149, -299.4882,  -95.3090,  234.8435,\n",
      "          35.7946,  100.4075,   25.6909,  208.0293,  -97.5634,  287.4185,\n",
      "        -135.6534,   25.7079, -146.1654, -183.7879,  326.0525,   -1.9754,\n",
      "          97.9761, -105.9708,  -26.5679,  105.8718,   -7.9916,  102.5728,\n",
      "          88.2670,  -10.6167], grad_fn=<SqueezeBackward4>)\n",
      "torch.Size([32])\n",
      "tensor([-0.0130, -0.3221, -0.1343, -2.4081,  0.2725, -0.5096,  0.9437,  0.3971,\n",
      "        -0.8904,  2.7399,  0.7183,  0.1857, -0.0626,  0.6610,  1.0374,  0.2503,\n",
      "         0.5053, -2.1089,  0.0930, -0.0555, -0.1158,  1.4827,  2.1302,  0.5563,\n",
      "        -0.7038,  0.7435, -1.1427, -1.4490,  0.4605, -0.0352, -1.4512, -1.7150],\n",
      "       grad_fn=<SqueezeBackward4>)\n",
      "torch.Size([32])\n",
      "tensor([ 1.4710,  1.0047,  0.7078, -2.1375, -0.3954,  1.2550,  0.0476, -1.3834,\n",
      "         0.3395, -0.3414,  0.3584, -0.2962,  0.3027,  1.8976, -1.5819,  1.4285,\n",
      "         0.4229, -0.6517, -1.6714,  0.2889,  0.4249, -1.1763, -1.0807,  0.6086,\n",
      "        -1.7939,  0.1894,  2.2980,  0.7456, -3.3391, -0.0447,  1.0954,  0.9304],\n",
      "       grad_fn=<SqueezeBackward4>)\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "input_dim = 16384\n",
    "output_dim = 32\n",
    "\n",
    "w = nn.Parameter(torch.randn(input_dim, output_dim))\n",
    "print(isinstance(w, torch.Tensor))\n",
    "print(type(w.data))\n",
    "x = nn.Parameter(torch.randn(input_dim))\n",
    "output = x @ w\n",
    "print(output)\n",
    "print(output.size())\n",
    "\n",
    "w = nn.Parameter(torch.randn(input_dim, output_dim) / np.sqrt(input_dim))\n",
    "output = x @ w\n",
    "print(output)\n",
    "print(output.size())\n",
    "\n",
    "w = nn.Parameter(nn.init.trunc_normal_(torch.empty(input_dim, output_dim), std=1 / np.sqrt(input_dim), a=-3, b=3))\n",
    "output = x @ w\n",
    "print(output)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7eb4044e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device() -> torch.device:\n",
    "    \"\"\"Try to use the GPU if possible, otherwise, use CPU.\"\"\"\n",
    "    if torch.mps.is_available():\n",
    "        return torch.device(f\"mps\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d1c7218",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    \"\"\"Simple linear layer.\"\"\"\n",
    "    def __init__(self, input_dim: int, output_dim: int):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(input_dim, output_dim) / np.sqrt(input_dim))\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return x @ self.weight\n",
    "\n",
    "class Cruncher(nn.Module):\n",
    "    def __init__(self, dim: int, num_layers: int):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            Linear(dim, dim)\n",
    "            for i in range(num_layers)\n",
    "        ])\n",
    "        self.final = Linear(dim, 1)\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # Apply linear layers\n",
    "        B, D = x.size()\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        # Apply final head\n",
    "        x = self.final(x)\n",
    "        assert x.size() == torch.Size([B, 1])\n",
    "        # Remove the last dimension\n",
    "        x = x.squeeze(-1)\n",
    "        assert x.size() == torch.Size([B])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98d01d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_parameters(model: nn.Module) -> int:\n",
    "    return sum(param.numel() for param in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d54b228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('layers.0.weight', 4096), ('layers.1.weight', 4096), ('final.weight', 64)]\n",
      "8256\n",
      "8256\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "# custom model\n",
    "D = 64\n",
    "num_layers = 2\n",
    "model = Cruncher(dim=D, num_layers=num_layers).to(get_device())\n",
    "\n",
    "param_sizes = [\n",
    "        (name, param.numel())\n",
    "        for name, param in model.state_dict().items()\n",
    "    ]\n",
    "\n",
    "print(param_sizes)\n",
    "\n",
    "num_parameters = get_num_parameters(model)\n",
    "print(num_parameters)\n",
    "print(D*D*2+D)\n",
    "\n",
    "device = get_device()\n",
    "model.to(device)\n",
    "\n",
    "# run\n",
    "B = 8\n",
    "x = torch.randn(B, D, device=device)\n",
    "y = model(x)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33d4762a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "import random\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62cb1b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD(torch.optim.Optimizer):\n",
    "    def __init__(self, params: Iterable[nn.Parameter], lr: float = 0.01):\n",
    "        super(SGD, self).__init__(params, dict(lr=lr))\n",
    "    def step(self):\n",
    "        for group in self.param_groups:\n",
    "            lr = group[\"lr\"]\n",
    "            for p in group[\"params\"]:\n",
    "                grad = p.grad.data\n",
    "                p.data -= lr * grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f45e6d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad(torch.optim.Optimizer):\n",
    "    def __init__(self, params: Iterable[nn.Parameter], lr: float = 0.01):\n",
    "        super(AdaGrad, self).__init__(params, dict(lr=lr))\n",
    "    def step(self):\n",
    "        for group in self.param_groups:\n",
    "            lr = group[\"lr\"]\n",
    "            for p in group[\"params\"]:\n",
    "                # Optimizer state\n",
    "                state = self.state[p]\n",
    "                grad = p.grad.data\n",
    "                # Get squared gradients g2 = sum_{i<t} g_i^2\n",
    "                g2 = state.get(\"g2\", torch.zeros_like(grad))\n",
    "                # Update optimizer state\n",
    "                g2 += torch.square(grad)\n",
    "                state[\"g2\"] = g2\n",
    "                # Update parameters\n",
    "                p.data -= lr * grad / torch.sqrt(g2 + 1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e425acbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "B = 2\n",
    "D = 4\n",
    "num_layers = 2\n",
    "model = Cruncher(dim=D, num_layers=num_layers).to(get_device())\n",
    "\n",
    "optimizer = AdaGrad(model.parameters(), lr=0.01)\n",
    "state = model.state_dict()  # @inspect state\n",
    "\n",
    "x = torch.randn(B, D, device=get_device())\n",
    "y = torch.tensor([4., 5.], device=get_device())\n",
    "pred_y = model(x)\n",
    "loss = F.mse_loss(input=pred_y, target=y)\n",
    "loss.backward()\n",
    "\n",
    "# Take a step\n",
    "optimizer.step()\n",
    "state = model.state_dict()  # @inspect state\n",
    "\n",
    "# Free up the memory (optional)\n",
    "optimizer.zero_grad(set_to_none=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7903f9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_parameters(model: nn.Module) -> int:\n",
    "    return sum(param.numel() for param in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7b48659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "36\n",
      "16\n",
      "496\n",
      "432\n"
     ]
    }
   ],
   "source": [
    "# Memory\n",
    "num_parameters = (D * D * num_layers) + D\n",
    "print(num_parameters)\n",
    "print(get_num_parameters(model))\n",
    "\n",
    "num_activations = B * D * num_layers\n",
    "print(num_activations)\n",
    "\n",
    "num_gradients = num_parameters\n",
    "\n",
    "num_optimizer_states = num_parameters \n",
    "\n",
    "total_memory = 4 * (num_parameters + num_activations + num_gradients + num_optimizer_states)\n",
    "\n",
    "print(total_memory)\n",
    "\n",
    "# compute\n",
    "flops = 6 * B * num_parameters \n",
    "print(flops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfea8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 1]\n",
      "  [2 3]]\n",
      "\n",
      " [[4 5]\n",
      "  [6 7]]]\n",
      "[[[0 4]\n",
      "  [2 6]]\n",
      "\n",
      " [[1 5]\n",
      "  [3 7]]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[[0,1],[2,3],[4,5]],[[6,7],[8,9],[10,11]]])\n",
    "print(A)\n",
    "At = A.T\n",
    "print(At)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa215183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002000000000000000\n",
      "0.001099999999999990\n"
     ]
    }
   ],
   "source": [
    "x1 = 2.0 / 1000\n",
    "print(f\"{x1:.18f}\")\n",
    "\n",
    "x2 = 1 + (1/10000 ) - (1 - 1/1000)\n",
    "print(f\"{x2:.18f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
